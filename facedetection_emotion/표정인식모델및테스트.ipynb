{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://yeong-jin-data-blog.tistory.com/entry/%EC%82%AC%EC%A0%84%ED%95%99%EC%8A%B5-%EB%AA%A8%EB%8D%B8-%EC%82%AC%EC%9A%A9\n",
        "<br>\n",
        "테스트 이미지 넣는 코드 (완료)"
      ],
      "metadata": {
        "id": "gaeFH4TauV1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1_try 사본에서 데이터셋을 얼굴로 확대한 버전으로 바꾼걸로 알고있음. 2_try에서는 모델 구조를 좀 바꿀 것임. 일단 테스트부터"
      ],
      "metadata": {
        "id": "SqqPOMBfp98l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PZnF1KCliE5",
        "outputId": "5f90f322-5cf5-42f2-f1c2-3dd2ddb75dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iOwBSSzSoKAt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import skimage.io as io\n",
        "from skimage.transform import resize\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from contextlib import contextmanager\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Nadam, RMSprop\n",
        "from keras.applications import VGG16 \n",
        "from keras.applications.vgg16 import preprocess_input \n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mzub6E8HfPgx",
        "outputId": "ee78f478-f9a7-4de0-b697-aaba1292f16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBs-WafDoy_K",
        "outputId": "c2f80d7f-a2bd-4b25-a264-a29f659da412"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "os.stat_result(st_mode=16832, st_ino=39, st_dev=38, st_nlink=2, st_uid=0, st_gid=0, st_size=4096, st_atime=1683563015, st_mtime=1682251402, st_ctime=1682251402)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "base_dir='/content/gdrive/MyDrive/emotion_/emotion_data3'\n",
        "os.stat(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "LgaYUAJ96QzZ",
        "outputId": "fafb3056-28bc-43e8-c5d3-2724a314d888"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint('train_image_happy',len(os.listdir(train_happy_dir)))\\nprint('train_image_happy',len(os.listdir(train_sad_dir)))\\nprint('train_image_happy',len(os.listdir(validation_happy_dir)))\\nprint('train_image_happy',len(os.listdir(validation_sad_dir)))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_dir=os.path.join(base_dir,'train')\n",
        "validation_dir=os.path.join(base_dir,'validation')\n",
        "train_happy_dir=os.path.join(train_dir,'happy_train')\n",
        "train_sad_dir=os.path.join(train_dir,'sad_train')\n",
        "validation_happy_dir=os.path.join(validation_dir,'happy_valid')\n",
        "validation_sad_dir=os.path.join(validation_dir,'sad_valid')\n",
        "'''\n",
        "print('train_image_happy',len(os.listdir(train_happy_dir)))\n",
        "print('train_image_happy',len(os.listdir(train_sad_dir)))\n",
        "print('train_image_happy',len(os.listdir(validation_happy_dir)))\n",
        "print('train_image_happy',len(os.listdir(validation_sad_dir)))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLjgn3yfR8SR"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.layers import Activation\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3),padding='same',activation='relu',\n",
        "                        input_shape=(50, 50, 1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3),padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(layers.Dense(1, activation='sigmoid')) #원래 1이었는데 2로 "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8efoBj6BYIST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndLy16isDhjI",
        "outputId": "6e48b7b0-d601-410a-8ec6-4263b37eba3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 50, 50, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 25, 25, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 25, 25, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 12, 12, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 6, 6, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               589952    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 718,337\n",
            "Trainable params: 717,121\n",
            "Non-trainable params: 1,216\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlmINgRvDu5B"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQGozy9bEC3K",
        "outputId": "d96590a2-6a32-4c0d-c34f-3895bd4f2339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 images belonging to 2 classes.\n",
            "Found 1200 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 모든 이미지를 1/255로 스케일을 조정\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(50, 50),\n",
        "        color_mode='grayscale',\n",
        "        batch_size=100,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(50, 50),\n",
        "        color_mode='grayscale',\n",
        "        batch_size=40,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "rYkb-qXwEpV0",
        "outputId": "67d48618-53eb-4990-d8f1-4e7af77e06ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-729a74174018>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'배치 데이터 크기:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'배치 레이블 크기:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             img = image_utils.load_img(\n\u001b[0m\u001b[1;32m    371\u001b[0m                 \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         raise TypeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('배치 데이터 크기:', data_batch.shape)\n",
        "    print('배치 레이블 크기:', labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRpQr2Jeza8G"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V36xD61ez5g2"
      },
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "1xuWFscwE-ri",
        "outputId": "6c7b32d6-3ab4-4fdf-d50c-5500246c7351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-cb84cf6e31dd>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-cb84cf6e31dd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m#callbacks=[callback],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m         )\n\u001b[0;32m-> 2636\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2637\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3683\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3685\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3686\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3687\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=40,\n",
        "      epochs=45,\n",
        "      #callbacks=[callback],\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXbtv2hfiaun",
        "outputId": "49d17aea-421b-4495-f36e-0830c7537047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('2_try.h5')"
      ],
      "metadata": {
        "id": "TufmnWM5ZY7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.load_model('/content/gdrive/MyDrive/emotion_/2_try.h5')\n"
      ],
      "metadata": {
        "id": "1UJJ9zlTZSjK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jpg_image_to_array(image_path,size):\n",
        "  image=Image.open(image_path)\n",
        "  im_arr=image.resize((size,size))\n",
        "  im_arr=np.fromstring(image.tobytes(),dtype=np.uint8)\n",
        "  #print(im_arr.shape)\n",
        "  im_arr=im_arr.reshape((image.size[0],image.size[1],1))\n",
        "  print(im_arr.shape)\n",
        "  \n",
        "  x=im_arr.astype(np.float32) \n",
        "  return x\n",
        "\n",
        "def image_array_to_1channel(arr):\n",
        "  arr_avg = (arr[:,:,0]+arr[:,:,1]+arr[:,:,2])/3   \n",
        "  return arr_avg"
      ],
      "metadata": {
        "id": "_WlF1bSznXBB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "plT-SDHMlQrS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "eR9xmkrVlTXS",
        "outputId": "0d168b73-1ca9-4749-e64f-79ccedd130ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2425fc41-f93d-4db0-be47-c92e289d9538\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2425fc41-f93d-4db0-be47-c92e289d9538\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving testimg3.jpg to testimg3.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=tf.keras.utils.load_img(\"/content/testimg3.jpg\",target_size=(50,50))\n",
        "arr=jpg_image_to_array(\"/content/testimg3.jpg\",50)\n",
        "plt.imshow(arr,cmap=plt.get_cmap('gray'))\n",
        "x_train=arr.reshape(1,50,50,1)/255.0\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "11IOWhqElb-D",
        "outputId": "6129972a-d8cd-43de-dd56-4e34bd8f2065"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e1fe2d086f3f>:4: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  im_arr=np.fromstring(image.tobytes(),dtype=np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 50, 1)\n",
            "(1, 50, 50, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(x_train)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTDs_kgZom9z",
        "outputId": "39175afa-ad01-4a02-cc01-a21304295834"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "[[3.699949e-06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(model.predict(x_train)>0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjJXq87TbLoS",
        "outputId": "edeef3b2-cb5c-48ad-b507-b3ca1e16174f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator.class_indices)\n",
        "print(validation_generator.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDQAxGn8rROQ",
        "outputId": "5f92028e-f09f-45d4-8e8f-4686ed19cf24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'happy_train': 0, 'sad_train': 1}\n",
            "{'happy_valid': 0, 'sad_valid': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "ytP8CwQvRzBC",
        "outputId": "0d8b4abe-169f-42bf-83c1-bff88c07f819"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7956176c-0f14-4320-b418-1c059b19c9e8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7956176c-0f14-4320-b418-1c059b19c9e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving testimg.jpg to testimg (1).jpg\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-575ce73b2319>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "uploaded=files.upload()\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  path='/content/' + fn\n",
        "  img=tf.keras.utils.load_img(path, target_size=(224, 224))\n",
        "  \n",
        "  x=tf.keras.utils.img_to_array(img)\n",
        "  x=np.expand_dims(x,axis=0)\n",
        "  images = np.vstack([x])\n",
        "  images=images.astype(np.float32)\n",
        "  x=x.astype(np.float32) \n",
        "  classes = model.predict(x)\n",
        "\n",
        "  print(classes[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYtWPTA0R3L7"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}